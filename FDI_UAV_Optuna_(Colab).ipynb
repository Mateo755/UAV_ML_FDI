{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCBdUyCj1cxhOwOXQyGlfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mateo755/UAV_ML_FDI/blob/main/FDI_UAV_Optuna_(Colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UAV Propeller Fault Detection System (Parrot Bebop 2)\n",
        "\n",
        "This project focuses on the development and validation of fault detection and isolation (FDI) methods for the propulsion system of the **Parrot Bebop 2** unmanned aerial vehicle (UAV). The analysis utilizes inertial sensor data (accelerometer and gyroscope) collected during real-world flight experiments.\n",
        "\n",
        "### Research Problem\n",
        "The primary objective is to classify the technical state of the propellers based on vibration signals. We analyze various fault scenarios across four rotors (A, B, C, D), distinguishing between nominal states and specific defects such as chipped edges or bent blades.\n",
        "\n",
        "### Methodology\n",
        "This notebook compares two signal processing approaches:\n",
        "1.  **Time Domain Analysis**\n",
        "2.  **Frequency Domain Analysis**\n",
        "\n",
        "Experiment tracking and performance visualization are managed via **Weights & Biases (W&B)**."
      ],
      "metadata": {
        "id": "ZPkfeiBvYMTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Environment Setup & Global Configuration\n",
        "Installation of necessary libraries (Weights & Biases for experiment tracking) and importing standard data science modules."
      ],
      "metadata": {
        "id": "aAsXj0bQYPxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "wBuNU_VVYiyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import optuna\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Adadelta, Adamax, Nadam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "import traceback"
      ],
      "metadata": {
        "id": "W-l7qMBMYNZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "5rSoKrSzYm7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory Data Analysis\n",
        "Initial inspection of the accelerometer and gyroscope data from the UAV. We examine the column structure."
      ],
      "metadata": {
        "id": "Lzmgu-V0Ytww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Time domain"
      ],
      "metadata": {
        "id": "dzm9tSDXY7ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/Normalized_data.zip"
      ],
      "metadata": {
        "id": "uNYX-PCdYuG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_time = pd.read_csv('/content/Normalized_data/Bebop2_16g_1kdps_normalized_0000.csv')\n",
        "df_time"
      ],
      "metadata": {
        "id": "tnvTK4vKYxBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_time.info()"
      ],
      "metadata": {
        "id": "3_Zi76BnYyR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Frequency Domain"
      ],
      "metadata": {
        "id": "mz_DOXEaY16a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/FFT_data.zip"
      ],
      "metadata": {
        "id": "aLwfhGFKY55i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq = pd.read_csv('/content/FFT_data/128_Hann_20_52/Bebop2_16g_FFT_ACCEL_128_Hann_20_52_0000.csv', header=None)\n",
        "df_freq"
      ],
      "metadata": {
        "id": "G9bMctTgY96o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq.info()"
      ],
      "metadata": {
        "id": "0kb2qEQWY_Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fault Scenario Mapping\n",
        "\n",
        "The Bebop 2 flight data is labeled using a 4-digit code (e.g., `1022`), defining the state of each propeller (A, B, C, D):\n",
        "* **0**: Nominal (Functional propeller).\n",
        "* **1**: Fault Type I (e.g., chipped edge).\n",
        "* **2**: Fault Type II (e.g., bent tip/severe damage).\n",
        "\n",
        "Below, we define the mapping of these physical scenarios to model class labels. Depending on the diagnostic granularity required, the problem can be framed as a **5-class problem** (aggregated by the number of faults) or a **20-class problem** (precise fault configuration)."
      ],
      "metadata": {
        "id": "uzoaYtfsZEi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Experiment Mode\n",
        "CLASS_MODE = \"5class\"   # Options: \"5class\" (aggregated) or \"20class\" (precise diagnosis)"
      ],
      "metadata": {
        "id": "_Ksm_yTMZE3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precise mapping for 20 unique scenarios (Parrot Bebop 2)\n",
        "scenario_to_class_20 = {\n",
        "    \"0000\": 0,  # Nominal state\n",
        "    \"1000\": 1, \"0100\": 2, \"0010\": 3, \"0001\": 4,     # Single faults (Type 1)\n",
        "    \"2000\": 5, \"0200\": 6, \"0020\": 7, \"0002\": 8,     # Single faults (Type 2)\n",
        "    \"1100\": 9, \"1020\": 10, \"1002\": 11, \"0120\": 12, \"0102\": 13, \"0022\": 14, # Dual faults\n",
        "    \"1120\": 15, \"1102\": 16, \"1022\": 17, \"0122\": 18, # Triple faults\n",
        "    \"1122\": 19, # All propellers faulty\n",
        "}\n",
        "\n",
        "# Simplified mapping (Number of faulty rotors)\n",
        "scenario_to_class_5 = {\n",
        "    \"0000\": 0,\n",
        "    \"1000\": 1, \"0100\": 1, \"0010\": 1, \"0001\": 1,\n",
        "    \"2000\": 1, \"0200\": 1, \"0020\": 1, \"0002\": 1,\n",
        "    \"1100\": 2, \"1020\": 2, \"1002\": 2, \"0120\": 2, \"0102\": 2, \"0022\": 2,\n",
        "    \"1120\": 3, \"1102\": 3, \"1022\": 3, \"0122\": 3,\n",
        "    \"1122\": 4,\n",
        "}\n",
        "\n",
        "if CLASS_MODE == \"5class\":\n",
        "    scenario_to_class = scenario_to_class_5\n",
        "elif CLASS_MODE == \"20class\":\n",
        "    scenario_to_class = scenario_to_class_20\n",
        "else:\n",
        "    raise ValueError(\"Invalid CLASS_MODE selected.\")\n",
        "\n",
        "NUM_CLASSES = len(set(scenario_to_class.values()))\n",
        "print(f\"Experiment Mode: {CLASS_MODE} | Total Classes: {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "LQntwDFzZH12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Time Domain Analysis, data preparation\n",
        "\n",
        "In this section, we process normalized time-series signals from the accelerometers and gyroscopes. Since the data represents a continuous flight stream, we apply a **sliding window** technique to segment the signal into fixed-length samples (e.g., 256 measurement points).\n",
        "\n"
      ],
      "metadata": {
        "id": "toqNSUaWZMFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Data Segmentation"
      ],
      "metadata": {
        "id": "ksDaq9m4ZPS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to normalized time-domain data\n",
        "DATA_DIR_TIME = r\"/content/Normalized_data\"\n",
        "SAMPLE_SIZE = 8             # Window length\n",
        "N_FEATURES = 24               # Input channels (e.g., 3-axis accel + 3-axis gyro per sensor)\n",
        "SENSOR_MODE = \"both\"          # \"accel\" + \"gyro\""
      ],
      "metadata": {
        "id": "nS4qmRjKZPFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_windows_from_df(df: pd.DataFrame, sample_size: int):\n",
        "    \"\"\"\n",
        "    Segments time-series data into non-overlapping windows.\n",
        "    \"\"\"\n",
        "    data = df.values.astype(\"float32\")\n",
        "    n_total = len(data)\n",
        "    n_windows = n_total // sample_size\n",
        "    if n_windows == 0:\n",
        "        return np.empty((0, sample_size, data.shape[1]), dtype=\"float32\")\n",
        "    data = data[:n_windows * sample_size]\n",
        "    windows = data.reshape(n_windows, sample_size, data.shape[1])\n",
        "    return windows"
      ],
      "metadata": {
        "id": "w2j0r69yZMcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing Pipeline\n",
        "The following loop iterates through all normalized CSV files in time domain. For each file, it:\n",
        "1.  Extracts the scenario code (e.g., `0000`) from the filename.\n",
        "2.  Checks if the scenario exists in our defined class mapping.\n",
        "3.  Loads the data and applies the sliding window segmentation.\n",
        "4.  Accumulates the processed windows (`X`) and corresponding labels (`y`) into a single dataset."
      ],
      "metadata": {
        "id": "zt6yDCdTZUBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data pass through window function\n",
        "\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "norm_data_files_pattern = os.path.join(DATA_DIR_TIME, \"Bebop2_16g_1kdps_normalized_*.csv\")\n",
        "\n",
        "for path in glob.glob(norm_data_files_pattern):\n",
        "    fname = os.path.basename(path)\n",
        "    # ostatni fragment po \"_\" to kod scenariusza, np. \"0000\"\n",
        "    scenario = os.path.splitext(fname)[0].split(\"_\")[-1]\n",
        "\n",
        "    if scenario not in scenario_to_class:\n",
        "        print(f\"Pomijam {fname} – scenariusz {scenario} nie jest w mapowaniu.\")\n",
        "        continue\n",
        "\n",
        "    label = scenario_to_class[scenario]\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # jeżeli w pliku są inne kolumny niż 24 sensory, tu można wybrać tylko potrzebne:\n",
        "    # df = df[[\"A_aX\",\"A_aY\",...,\"D_gZ\"]]\n",
        "\n",
        "    windows = make_windows_from_df(df, SAMPLE_SIZE)\n",
        "    if windows.shape[0] == 0:\n",
        "        print(f\"Za mało danych w {fname} na choć jedno okno, pomijam.\")\n",
        "        continue\n",
        "\n",
        "    X_list.append(windows)\n",
        "    y_list.append(np.full((windows.shape[0],), label, dtype=\"int32\"))\n",
        "\n",
        "X = np.concatenate(X_list, axis=0)  # (N, SAMPLE_SIZE, 24)\n",
        "y = np.concatenate(y_list, axis=0)  # (N,)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape, \"unikalne etykiety:\", np.unique(y))\n",
        "\n",
        "input_shape = (SAMPLE_SIZE, N_FEATURES)\n",
        "print(\"input_shape modelu:\", input_shape)"
      ],
      "metadata": {
        "id": "Y-kvvG67ZUYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Frequency Domain Analysis (FFT)\n",
        "\n",
        "Mechanical faults in rotating components (such as propellers) generate distinct vibration signatures that are often most discernible in the frequency spectrum.\n",
        "\n",
        "In this experiment, we utilize data pre-processed via **Fast Fourier Transform (FFT)** using a Hann window to mitigate spectral leakage, which is already done in repo. The input features are vectors of spectral coefficients for each sensor axis."
      ],
      "metadata": {
        "id": "UoL2KH_XZXLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Spectral Data Structure\n",
        "The FFT files contain metadata within their filenames (window length, window type, frequency range). The following code parses this information and loads the corresponding spectral coefficients."
      ],
      "metadata": {
        "id": "bhEtio4xZY9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration for FFT Data\n",
        "FFT_ROOT      = \"FFT_data\"\n",
        "FFT_CONFIG    = \"128_Hann_20_52\"     # Specific window/range configuration\n",
        "SENSOR_MODE   = \"both\"               # \"accel\", \"gyro\", or \"both\"\n",
        "SAMPLING_RATE = 500.0                # Sampling rate for Bebop 2 inertial sensors\n",
        "\n",
        "# liczba osi na jeden typ czujnika\n",
        "N_AXES_SINGLE = 12\n",
        "N_AXES = 12 if SENSOR_MODE in (\"accel\", \"gyro\") else 24\n",
        "\n",
        "fft_dir = os.path.join(FFT_ROOT, FFT_CONFIG)"
      ],
      "metadata": {
        "id": "fOHXpGaTZXes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_fft_info(fft_dir, sampling_rate=500.0):\n",
        "    \"\"\"\n",
        "    Extracts FFT parameters encoded in the data folder name and converts them\n",
        "    into physical frequency values.\n",
        "\n",
        "    The function assumes the folder name follows the format:\n",
        "    'WindowLength_WindowType_StartBin_StopBin' (e.g., '128_Hann_20_52').\n",
        "    \"\"\"\n",
        "\n",
        "    folder_name = os.path.basename(os.path.normpath(fft_dir))\n",
        "    parts = folder_name.split(\"_\")          # np. [\"128\",\"Hann\",\"20\",\"52\"]\n",
        "    measuringWindowLength = int(parts[0])   # 128\n",
        "    rangeStart = int(parts[-2])             # 20\n",
        "    rangeStop  = int(parts[-1])             # 52\n",
        "\n",
        "    freq_res = sampling_rate / measuringWindowLength\n",
        "    f_start  = (rangeStart - 1) * freq_res\n",
        "    f_stop   = rangeStop * freq_res\n",
        "\n",
        "    print(f\"Folder FFT: {folder_name}\")\n",
        "    print(f\"measuringWindowLength = {measuringWindowLength}\")\n",
        "    print(f\"Zakres binów: {rangeStart}–{rangeStop}\")\n",
        "    print(f\"Rozdzielczość częstotliwości: {freq_res:.3f} Hz\")\n",
        "    print(f\"Zakres częstotliwości: {f_start:.1f} Hz – {f_stop:.1f} Hz\")\n",
        "\n",
        "    return measuringWindowLength, rangeStart, rangeStop, freq_res, f_start, f_stop"
      ],
      "metadata": {
        "id": "p-yEwGWeZcfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "measuringWindowLength, rangeStart, rangeStop, freq_res, f_start, f_stop = print_fft_info(fft_dir, SAMPLING_RATE)"
      ],
      "metadata": {
        "id": "Qx84q7F_Zd4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Discovery & Categorization\n",
        "This block scans the directory for all CSV files and organizes them into dictionaries based on the sensor type (**ACCEL** vs. **GYRO**). It parses the filename to extract the specific fault scenario code (e.g., `0000`, `1022`), using it as a key for quick lookup during the data loading phase."
      ],
      "metadata": {
        "id": "Hm2eX53MZgvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scan directory and map file paths to scenarios based on sensor type (ACCEL/GYRO)\n",
        "\n",
        "all_files = glob.glob(os.path.join(fft_dir, \"*.csv\"))\n",
        "\n",
        "accel_files = {}  # scenario -> ścieżka\n",
        "gyro_files  = {}\n",
        "\n",
        "for path in all_files:\n",
        "    fname = os.path.basename(path)\n",
        "    parts = fname.split(\"_\")\n",
        "    # przykład: Bebop2_16g_FFT_ACCEL_128_Hann_20_52_0000.csv\n",
        "    # indeksy:   0      1   2   3     4    5    6   7   8\n",
        "    sensor_type = parts[3]              # \"ACCEL\" albo \"GYRO\"\n",
        "    scenario    = os.path.splitext(parts[-1])[0]  # \"0000\" itd.\n",
        "\n",
        "    if sensor_type == \"ACCEL\":\n",
        "        accel_files[scenario] = path\n",
        "    elif sensor_type == \"GYRO\":\n",
        "        gyro_files[scenario] = path\n",
        "\n",
        "print(\"Znaleziono ACCEL dla scenariuszy:\", sorted(accel_files.keys()))\n",
        "print(\"Znaleziono GYRO  dla scenariuszy:\", sorted(gyro_files.keys()))\n"
      ],
      "metadata": {
        "id": "T-KQMuUjZnI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading & Sensor Fusion\n",
        "In this step, we aggregate the spectral data based on the selected `SENSOR_MODE`.\n",
        "* **Accel/Gyro:** Loads only the specified sensor data.\n",
        "* **Both:** Loads both accelerometer and gyroscope files for the same scenario, verifying consistency, and concatenates them along the feature axis to create a unified feature vector (e.g., 24 input channels)."
      ],
      "metadata": {
        "id": "iK8NNsoiZkUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fft_file(path, n_axes=N_AXES_SINGLE):\n",
        "    \"\"\"\n",
        "    Loads spectral data from a CSV file and reshapes it into a 3D tensor.\n",
        "\n",
        "    The function reads a flat CSV (assuming no header), calculates the number\n",
        "    of frequency bins based on the total columns and specified axes, and\n",
        "    restructures the data.\n",
        "    \"\"\"\n",
        "\n",
        "    # jeśli okaże się, że plik ma nagłówek – zmień na header=0\n",
        "    df = pd.read_csv(path, header=None)\n",
        "    data = df.values.astype(\"float32\")   # (n_okien, n_features)\n",
        "    n_features = data.shape[1]\n",
        "\n",
        "    if n_features % n_axes != 0:\n",
        "        raise ValueError(f\"{os.path.basename(path)}: {n_features} kolumn \"\n",
        "                         f\"nie dzieli się przez {n_axes} osi.\")\n",
        "\n",
        "    n_freq_bins = n_features // n_axes\n",
        "    data_3d = data.reshape(-1, n_freq_bins, n_axes)  # (n_okien, n_freq_bins, n_axes)\n",
        "    return data_3d, n_freq_bins"
      ],
      "metadata": {
        "id": "291e8GCKZkjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_list = []\n",
        "y_list = []\n",
        "n_freq_bins_global = None\n",
        "\n",
        "for scenario, label in scenario_to_class.items():\n",
        "    cur_X = None\n",
        "\n",
        "    if SENSOR_MODE == \"accel\":\n",
        "        path = accel_files.get(scenario)\n",
        "        if path is None:\n",
        "            print(f\"[ACCEL] brak pliku dla scenariusza {scenario}, pomijam.\")\n",
        "            continue\n",
        "        accel_data, n_freq_bins = load_fft_file(path)\n",
        "        cur_X = accel_data   # (n_okien, n_freq_bins, 12)\n",
        "\n",
        "    elif SENSOR_MODE == \"gyro\":\n",
        "        path = gyro_files.get(scenario)\n",
        "        if path is None:\n",
        "            print(f\"[GYRO] brak pliku dla scenariusza {scenario}, pomijam.\")\n",
        "            continue\n",
        "        gyro_data, n_freq_bins = load_fft_file(path)\n",
        "        cur_X = gyro_data    # (n_okien, n_freq_bins, 12)\n",
        "\n",
        "    elif SENSOR_MODE == \"both\":\n",
        "        path_a = accel_files.get(scenario)\n",
        "        path_g = gyro_files.get(scenario)\n",
        "        if path_a is None or path_g is None:\n",
        "            print(f\"[BOTH] brak ACCEL lub GYRO dla {scenario}, pomijam.\")\n",
        "            continue\n",
        "\n",
        "        accel_data, n_freq_bins_a = load_fft_file(path_a, n_axes=N_AXES_SINGLE)\n",
        "        gyro_data,  n_freq_bins_g = load_fft_file(path_g, n_axes=N_AXES_SINGLE)\n",
        "\n",
        "        if accel_data.shape[0] != gyro_data.shape[0] or n_freq_bins_a != n_freq_bins_g:\n",
        "            raise ValueError(f\"Niezgodne rozmiary ACCEL/GYRO dla scenariusza {scenario}\")\n",
        "\n",
        "        # sklejanie po osi „kanałów”: 12 (ACCEL) + 12 (GYRO) = 24\n",
        "        cur_X = np.concatenate([accel_data, gyro_data], axis=-1)  # (..., n_freq_bins, 24)\n",
        "        n_freq_bins = n_freq_bins_a\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"SENSOR_MODE musi być 'accel', 'gyro' albo 'both'\")\n",
        "\n",
        "    # ustaw / sprawdź globalną liczbę binów\n",
        "    if n_freq_bins_global is None:\n",
        "        n_freq_bins_global = n_freq_bins\n",
        "    elif n_freq_bins_global != n_freq_bins:\n",
        "        raise ValueError(\"Różne n_freq_bins między plikami, coś jest nie tak.\")\n",
        "\n",
        "    X_list.append(cur_X)\n",
        "    y_list.append(np.full((cur_X.shape[0],), label, dtype=\"int32\"))\n",
        "\n",
        "# Sklejenie wszystkiego\n",
        "X = np.concatenate(X_list, axis=0)   # (N, n_freq_bins, N_AXES)\n",
        "y = np.concatenate(y_list, axis=0)   # (N,)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape, \"unikalne etykiety:\", np.unique(y))\n",
        "\n",
        "n_freq_bins = n_freq_bins_global\n",
        "input_shape = (n_freq_bins, N_AXES)\n",
        "print(\"input_shape modelu:\", input_shape)\n"
      ],
      "metadata": {
        "id": "10GDeEsEZpgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. OPTUNA"
      ],
      "metadata": {
        "id": "hIeFROpvZs8_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSfTG5E6ZuwY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}